"""
Interview Analysis API Routes
é¢è¯•ç»“æœåˆ†æAPIè·¯ç”±
"""

from flask import Blueprint, request, jsonify, current_app
from flask_jwt_extended import jwt_required, get_jwt_identity
from app.extensions import db
from app.models.question import InterviewSession, Answer, Question
from app.services.interview_analyzer import InterviewAnalyzer
from app.utils.response import success_response, error_response
from datetime import datetime, timedelta
import logging

# åˆ›å»ºè“å›¾
analysis = Blueprint('analysis', __name__)
logger = logging.getLogger(__name__)

@analysis.route('/test', methods=['GET'])
def test_route():
    """æµ‹è¯•è·¯ç”±"""
    print("ğŸ” [DEBUG] æµ‹è¯•è·¯ç”±è¢«è°ƒç”¨!")
    return {"message": "æµ‹è¯•è·¯ç”±å·¥ä½œæ­£å¸¸", "success": True}

@analysis.route('/test-no-auth/<session_id>', methods=['GET'])
def test_no_auth(session_id):
    """æ— è®¤è¯æµ‹è¯•è·¯ç”±"""
    print(f"ğŸ” [DEBUG] æ— è®¤è¯æµ‹è¯•è·¯ç”±è¢«è°ƒç”¨: session_id={session_id}")
    try:
        from app.models.question import InterviewSession
        total_sessions = InterviewSession.query.count()
        print(f"ğŸ” [DEBUG] æ•°æ®åº“ä¸­æ€»å…±æœ‰ {total_sessions} ä¸ªä¼šè¯")
        
        session = InterviewSession.query.filter_by(session_id=session_id).first()
        if session:
            print(f"ğŸ” [DEBUG] æ‰¾åˆ°ä¼šè¯: {session.session_id}, user_id: {session.user_id}")
            return {"message": f"æ‰¾åˆ°ä¼šè¯ {session_id}", "success": True, "user_id": session.user_id}
        else:
            print(f"ğŸ” [DEBUG] æœªæ‰¾åˆ°ä¼šè¯: {session_id}")
            return {"message": f"æœªæ‰¾åˆ°ä¼šè¯ {session_id}", "success": False}
    except Exception as e:
        print(f"ğŸ” [DEBUG] å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        return {"message": f"é”™è¯¯: {str(e)}", "success": False}

@analysis.route('/session/<session_id>', methods=['GET'])
@jwt_required()
def analyze_session(session_id):
    """
    åˆ†æé¢è¯•ä¼šè¯ç»“æœ
    
    Args:
        session_id: é¢è¯•ä¼šè¯ID
        
    Returns:
        å®Œæ•´çš„é¢è¯•åˆ†æç»“æœ
    """
    try:
        user_id = int(get_jwt_identity())
        logger.info(f"ğŸ” [DEBUG] åˆ†æä¼šè¯è¯·æ±‚: session_id={session_id}, user_id={user_id}")
        print(f"ğŸ” [DEBUG] åˆ†æä¼šè¯è¯·æ±‚: session_id={session_id}, user_id={user_id}")
        
        # è°ƒè¯•ï¼šæ£€æŸ¥æ•°æ®åº“è¿æ¥
        total_sessions = InterviewSession.query.count()
        logger.info(f"æ•°æ®åº“ä¸­æ€»å…±æœ‰ {total_sessions} ä¸ªä¼šè¯")
        print(f"ğŸ” [DEBUG] æ•°æ®åº“ä¸­æ€»å…±æœ‰ {total_sessions} ä¸ªä¼šè¯")
        
        # éªŒè¯ä¼šè¯å­˜åœ¨
        session = InterviewSession.query.filter_by(
            session_id=session_id,
            user_id=user_id
        ).first()
        
        if not session:
            logger.warning(f"ä¼šè¯æœªæ‰¾åˆ°: session_id={session_id}, user_id={user_id}")
            print(f"ğŸ” [DEBUG] ä¼šè¯æœªæ‰¾åˆ°: session_id={session_id}, user_id={user_id}")
            # è°ƒè¯•ï¼šæŸ¥çœ‹æ˜¯å¦æœ‰åŒåä¼šè¯
            all_sessions = InterviewSession.query.filter_by(session_id=session_id).all()
            logger.info(f"åŒsession_idçš„æ‰€æœ‰ä¼šè¯: {[s.user_id for s in all_sessions]}")
            print(f"ğŸ” [DEBUG] åŒsession_idçš„æ‰€æœ‰ä¼šè¯: {[s.user_id for s in all_sessions]}")
            # è°ƒè¯•ï¼šæŸ¥çœ‹è¯¥ç”¨æˆ·çš„æ‰€æœ‰ä¼šè¯
            user_sessions = InterviewSession.query.filter_by(user_id=user_id).all()
            logger.info(f"ç”¨æˆ· {user_id} çš„æ‰€æœ‰ä¼šè¯: {[s.session_id for s in user_sessions]}")
            print(f"ğŸ” [DEBUG] ç”¨æˆ· {user_id} çš„æ‰€æœ‰ä¼šè¯: {[s.session_id for s in user_sessions]}")
            return error_response("é¢è¯•ä¼šè¯ä¸å­˜åœ¨", 404)
        
        print(f"ğŸ” [DEBUG] æ‰¾åˆ°ä¼šè¯: {session.session_id}, çŠ¶æ€: {session.status}")
        
        # æ£€æŸ¥é¢è¯•çŠ¶æ€ - å…è®¸åˆ†æè¿›è¡Œä¸­çš„é¢è¯•
        if session.status in ['created', 'ready']:
            return error_response("é¢è¯•å°šæœªå¼€å§‹ï¼Œæ— æ³•è¿›è¡Œåˆ†æ", 400)
        
        # æ‰§è¡Œåˆ†æ
        print(f"ğŸ” [DEBUG] å¼€å§‹æ‰§è¡Œåˆ†æ...")
        analyzer = InterviewAnalyzer()
        analysis_result = analyzer.analyze_interview_session(session_id, user_id)
        
        if 'error' in analysis_result:
            print(f"ğŸ” [DEBUG] åˆ†æå¤±è´¥: {analysis_result['error']}")
            return error_response(f"åˆ†æå¤±è´¥: {analysis_result['error']}", 500)
        
        print(f"ğŸ” [DEBUG] åˆ†ææˆåŠŸï¼Œè¿”å›ç»“æœ")
        return success_response(analysis_result, "é¢è¯•åˆ†æå®Œæˆ")
        
    except Exception as e:
        logger.error(f"é¢è¯•ä¼šè¯åˆ†æå¤±è´¥: {str(e)}")
        print(f"ğŸ” [DEBUG] å¼‚å¸¸: {str(e)}")
        import traceback
        traceback.print_exc()
        return error_response(f"åˆ†æå¤±è´¥: {str(e)}", 500)


@analysis.route('/report/<session_id>', methods=['GET'])
@jwt_required()
def generate_report(session_id):
    """
    ç”Ÿæˆé¢è¯•æŠ¥å‘Š
    
    Args:
        session_id: é¢è¯•ä¼šè¯ID
        
    Returns:
        æ ¼å¼åŒ–çš„é¢è¯•æŠ¥å‘Š
    """
    try:
        user_id = int(get_jwt_identity())
        
        # è·å–åˆ†æç»“æœ
        analyzer = InterviewAnalyzer()
        analysis_result = analyzer.analyze_interview_session(session_id, user_id)
        
        if 'error' in analysis_result:
            return error_response(f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {analysis_result['error']}", 500)
        
        # ç”Ÿæˆæ ¼å¼åŒ–æŠ¥å‘Š
        report = _format_interview_report(analysis_result)
        
        return success_response(report, "é¢è¯•æŠ¥å‘Šç”ŸæˆæˆåŠŸ")
        
    except Exception as e:
        logger.error(f"é¢è¯•æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}")
        return error_response(f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}", 500)


@analysis.route('/visualization/<session_id>', methods=['GET'])
@jwt_required()
def get_visualization_data(session_id):
    """
    è·å–å¯è§†åŒ–æ•°æ®
    
    Args:
        session_id: é¢è¯•ä¼šè¯ID
        
    Returns:
        å¯è§†åŒ–å›¾è¡¨æ•°æ®
    """
    try:
        user_id = int(get_jwt_identity())
        
        # è·å–åˆ†æç»“æœ
        analyzer = InterviewAnalyzer()
        analysis_result = analyzer.analyze_interview_session(session_id, user_id)
        
        if 'error' in analysis_result:
            return error_response(f"å¯è§†åŒ–æ•°æ®è·å–å¤±è´¥: {analysis_result['error']}", 500)
        
        # è¿”å›å¯è§†åŒ–æ•°æ®
        viz_data = analysis_result.get('visualization_data', {})
        
        return success_response(viz_data, "å¯è§†åŒ–æ•°æ®è·å–æˆåŠŸ")
        
    except Exception as e:
        logger.error(f"å¯è§†åŒ–æ•°æ®è·å–å¤±è´¥: {str(e)}")
        return error_response(f"æ•°æ®è·å–å¤±è´¥: {str(e)}", 500)


@analysis.route('/statistics', methods=['GET'])
@jwt_required()
def get_user_statistics():
    """
    è·å–ç”¨æˆ·é¢è¯•ç»Ÿè®¡æ•°æ®
    
    Returns:
        ç”¨æˆ·çš„æ•´ä½“é¢è¯•ç»Ÿè®¡
    """
    try:
        user_id = int(get_jwt_identity())
        
        # è·å–æ—¶é—´èŒƒå›´å‚æ•°
        days = request.args.get('days', 30, type=int)
        start_date = datetime.utcnow() - timedelta(days=days)
        
        # æŸ¥è¯¢ç”¨æˆ·çš„é¢è¯•ä¼šè¯
        sessions = InterviewSession.query.filter(
            InterviewSession.user_id == user_id,
            InterviewSession.created_at >= start_date,
            InterviewSession.status.in_(['completed', 'paused'])
        ).all()
        
        if not sessions:
            return success_response({
                'total_interviews': 0,
                'average_score': 0,
                'improvement_trend': [],
                'performance_by_type': {},
                'time_distribution': {}
            }, "æš‚æ— é¢è¯•æ•°æ®")
        
        # è®¡ç®—ç»Ÿè®¡æ•°æ®
        stats = _calculate_user_statistics(sessions, user_id)
        
        return success_response(stats, "ç»Ÿè®¡æ•°æ®è·å–æˆåŠŸ")
        
    except Exception as e:
        logger.error(f"ç»Ÿè®¡æ•°æ®è·å–å¤±è´¥: {str(e)}")
        return error_response(f"ç»Ÿè®¡æ•°æ®è·å–å¤±è´¥: {str(e)}", 500)


@analysis.route('/comparison', methods=['POST'])
@jwt_required()
def compare_interviews():
    """
    æ¯”è¾ƒå¤šä¸ªé¢è¯•ç»“æœ
    
    Returns:
        é¢è¯•ç»“æœå¯¹æ¯”åˆ†æ
    """
    try:
        user_id = int(get_jwt_identity())
        data = request.get_json()
        
        session_ids = data.get('session_ids', [])
        if len(session_ids) < 2:
            return error_response("è‡³å°‘éœ€è¦ä¸¤ä¸ªé¢è¯•ä¼šè¯è¿›è¡Œæ¯”è¾ƒ", 400)
        
        if len(session_ids) > 5:
            return error_response("æœ€å¤šåªèƒ½æ¯”è¾ƒ5ä¸ªé¢è¯•ä¼šè¯", 400)
        
        # éªŒè¯æ‰€æœ‰ä¼šè¯éƒ½å±äºè¯¥ç”¨æˆ·
        sessions = InterviewSession.query.filter(
            InterviewSession.session_id.in_(session_ids),
            InterviewSession.user_id == user_id
        ).all()
        
        if len(sessions) != len(session_ids):
            return error_response("éƒ¨åˆ†é¢è¯•ä¼šè¯ä¸å­˜åœ¨æˆ–æ— æƒè®¿é—®", 404)
        
        # æ‰§è¡Œæ¯”è¾ƒåˆ†æ
        comparison_result = _compare_interview_sessions(session_ids, user_id)
        
        return success_response(comparison_result, "é¢è¯•æ¯”è¾ƒåˆ†æå®Œæˆ")
        
    except Exception as e:
        logger.error(f"é¢è¯•æ¯”è¾ƒåˆ†æå¤±è´¥: {str(e)}")
        return error_response(f"æ¯”è¾ƒåˆ†æå¤±è´¥: {str(e)}", 500)


@analysis.route('/insights/<session_id>', methods=['GET'])
@jwt_required()
def get_detailed_insights(session_id):
    """
    è·å–è¯¦ç»†çš„é¢è¯•æ´å¯Ÿ
    
    Args:
        session_id: é¢è¯•ä¼šè¯ID
        
    Returns:
        è¯¦ç»†çš„é¢è¯•åˆ†ææ´å¯Ÿ
    """
    try:
        user_id = int(get_jwt_identity())
        
        # è·å–åŸºç¡€åˆ†æ
        analyzer = InterviewAnalyzer()
        analysis_result = analyzer.analyze_interview_session(session_id, user_id)
        
        if 'error' in analysis_result:
            return error_response(f"æ´å¯Ÿåˆ†æå¤±è´¥: {analysis_result['error']}", 500)
        
        # ç”Ÿæˆæ·±åº¦æ´å¯Ÿ
        insights = _generate_detailed_insights(analysis_result, session_id, user_id)
        
        return success_response(insights, "è¯¦ç»†æ´å¯Ÿåˆ†æå®Œæˆ")
        
    except Exception as e:
        logger.error(f"è¯¦ç»†æ´å¯Ÿåˆ†æå¤±è´¥: {str(e)}")
        return error_response(f"æ´å¯Ÿåˆ†æå¤±è´¥: {str(e)}", 500)


@analysis.route('/export/<session_id>', methods=['GET'])
@jwt_required()
def export_analysis(session_id):
    """
    å¯¼å‡ºé¢è¯•åˆ†æç»“æœ
    
    Args:
        session_id: é¢è¯•ä¼šè¯ID
        
    Returns:
        å¯å¯¼å‡ºçš„é¢è¯•åˆ†ææ•°æ®
    """
    try:
        user_id = int(get_jwt_identity())
        export_format = request.args.get('format', 'json')
        
        # è·å–åˆ†æç»“æœ
        analyzer = InterviewAnalyzer()
        analysis_result = analyzer.analyze_interview_session(session_id, user_id)
        
        if 'error' in analysis_result:
            return error_response(f"å¯¼å‡ºå¤±è´¥: {analysis_result['error']}", 500)
        
        # æ ¼å¼åŒ–å¯¼å‡ºæ•°æ®
        export_data = _format_export_data(analysis_result, export_format)
        
        return success_response(export_data, f"é¢è¯•åˆ†ææ•°æ®å¯¼å‡ºæˆåŠŸ({export_format})")
        
    except Exception as e:
        logger.error(f"é¢è¯•åˆ†æå¯¼å‡ºå¤±è´¥: {str(e)}")
        return error_response(f"å¯¼å‡ºå¤±è´¥: {str(e)}", 500)


# è¾…åŠ©å‡½æ•°
def _format_interview_report(analysis_result):
    """æ ¼å¼åŒ–é¢è¯•æŠ¥å‘Š"""
    report = {
        'report_id': f"report_{analysis_result['session_info']['session_id']}",
        'generated_at': datetime.utcnow().isoformat(),
        'session_summary': {
            'title': analysis_result['session_info']['title'],
            'type': analysis_result['session_info']['interview_type'],
            'duration': analysis_result['session_info']['duration_minutes'],
            'completion_rate': analysis_result['performance_metrics']['completion_rate']
        },
        'performance_overview': {
            'overall_score': round(analysis_result['overall_score'], 1),
            'grade': _get_performance_grade(analysis_result['overall_score']),
            'ranking_percentile': _calculate_percentile(analysis_result['overall_score'])
        },
        'section_performance': {},
        'key_findings': {
            'strengths': analysis_result['strengths'],
            'areas_for_improvement': analysis_result['weaknesses'],
            'recommendations': analysis_result['recommendations']
        },
        'detailed_analysis': analysis_result['detailed_feedback'],
        'next_steps': analysis_result['detailed_feedback'].get('next_steps', [])
    }
    
    # æ ¼å¼åŒ–å„éƒ¨åˆ†è¡¨ç°
    for section, scores in analysis_result['section_scores'].items():
        report['section_performance'][section] = {
            'score': round(scores['average_score'], 1),
            'grade': _get_performance_grade(scores['average_score']),
            'question_count': scores['count'],
            'best_score': round(scores['max_score'], 1),
            'lowest_score': round(scores['min_score'], 1)
        }
    
    return report


def _calculate_user_statistics(sessions, user_id):
    """è®¡ç®—ç”¨æˆ·ç»Ÿè®¡æ•°æ®"""
    analyzer = InterviewAnalyzer()
    stats = {
        'total_interviews': len(sessions),
        'average_score': 0,
        'improvement_trend': [],
        'performance_by_type': {},
        'time_distribution': {},
        'score_distribution': {
            'excellent': 0,
            'good': 0,
            'average': 0,
            'below_average': 0
        }
    }
    
    # æ”¶é›†æ‰€æœ‰åˆ†æç»“æœ
    analysis_results = []
    for session in sessions:
        try:
            result = analyzer.analyze_interview_session(session.session_id, user_id)
            if 'error' not in result:
                analysis_results.append(result)
        except Exception:
            continue
    
    if not analysis_results:
        return stats
    
    # è®¡ç®—å¹³å‡åˆ†
    scores = [result['overall_score'] for result in analysis_results]
    stats['average_score'] = round(sum(scores) / len(scores), 1)
    
    # æ”¹è¿›è¶‹åŠ¿
    sorted_results = sorted(analysis_results, 
                          key=lambda x: x['session_info']['start_time'] or '')
    stats['improvement_trend'] = [
        {
            'date': result['session_info']['start_time'][:10] if result['session_info']['start_time'] else '',
            'score': round(result['overall_score'], 1)
        }
        for result in sorted_results[-10:]  # æœ€è¿‘10æ¬¡
    ]
    
    # æŒ‰ç±»å‹åˆ†æ
    type_scores = {}
    for result in analysis_results:
        interview_type = result['session_info']['interview_type']
        if interview_type not in type_scores:
            type_scores[interview_type] = []
        type_scores[interview_type].append(result['overall_score'])
    
    for interview_type, type_score_list in type_scores.items():
        stats['performance_by_type'][interview_type] = {
            'average_score': round(sum(type_score_list) / len(type_score_list), 1),
            'count': len(type_score_list),
            'best_score': round(max(type_score_list), 1)
        }
    
    # åˆ†æ•°åˆ†å¸ƒ
    for score in scores:
        if score >= 90:
            stats['score_distribution']['excellent'] += 1
        elif score >= 75:
            stats['score_distribution']['good'] += 1
        elif score >= 60:
            stats['score_distribution']['average'] += 1
        else:
            stats['score_distribution']['below_average'] += 1
    
    return stats


def _compare_interview_sessions(session_ids, user_id):
    """æ¯”è¾ƒå¤šä¸ªé¢è¯•ä¼šè¯"""
    analyzer = InterviewAnalyzer()
    comparison = {
        'sessions': [],
        'comparison_metrics': {},
        'improvement_analysis': {},
        'recommendations': []
    }
    
    # è·å–æ‰€æœ‰åˆ†æç»“æœ
    analysis_results = []
    for session_id in session_ids:
        try:
            result = analyzer.analyze_interview_session(session_id, user_id)
            if 'error' not in result:
                analysis_results.append(result)
        except Exception:
            continue
    
    if len(analysis_results) < 2:
        return {'error': 'æ— æ³•è·å–è¶³å¤Ÿçš„åˆ†ææ•°æ®è¿›è¡Œæ¯”è¾ƒ'}
    
    # åŸºç¡€æ¯”è¾ƒæ•°æ®
    for result in analysis_results:
        session_summary = {
            'session_id': result['session_info']['session_id'],
            'title': result['session_info']['title'],
            'type': result['session_info']['interview_type'],
            'date': result['session_info']['start_time'][:10] if result['session_info']['start_time'] else '',
            'overall_score': round(result['overall_score'], 1),
            'completion_rate': result['performance_metrics']['completion_rate'],
            'duration': result['session_info']['duration_minutes']
        }
        comparison['sessions'].append(session_summary)
    
    # æ¯”è¾ƒæŒ‡æ ‡
    scores = [result['overall_score'] for result in analysis_results]
    comparison['comparison_metrics'] = {
        'score_range': {
            'highest': round(max(scores), 1),
            'lowest': round(min(scores), 1),
            'difference': round(max(scores) - min(scores), 1)
        },
        'average_score': round(sum(scores) / len(scores), 1),
        'consistency': round(100 - (max(scores) - min(scores)), 1)  # ä¸€è‡´æ€§æŒ‡æ ‡
    }
    
    # æ”¹è¿›åˆ†æ
    if len(analysis_results) > 1:
        latest_score = analysis_results[-1]['overall_score']
        earliest_score = analysis_results[0]['overall_score']
        comparison['improvement_analysis'] = {
            'trend': 'improving' if latest_score > earliest_score else 'declining' if latest_score < earliest_score else 'stable',
            'improvement_rate': round(latest_score - earliest_score, 1),
            'best_performance': max(analysis_results, key=lambda x: x['overall_score'])['session_info']['session_id']
        }
    
    return comparison


def _generate_detailed_insights(analysis_result, session_id, user_id):
    """ç”Ÿæˆè¯¦ç»†æ´å¯Ÿ"""
    insights = {
        'performance_insights': [],
        'behavioral_patterns': [],
        'technical_assessment': {},
        'time_management': {},
        'communication_effectiveness': {},
        'growth_opportunities': []
    }
    
    overall_score = analysis_result['overall_score']
    answer_analysis = analysis_result.get('answer_analysis', [])
    
    # è¡¨ç°æ´å¯Ÿ
    if overall_score >= 85:
        insights['performance_insights'].append("å±•ç°å‡ºè‰²çš„é¢è¯•æŠ€èƒ½ï¼Œå›ç­”è´¨é‡å§‹ç»ˆä¿æŒé«˜æ°´å‡†")
    elif overall_score >= 70:
        insights['performance_insights'].append("é¢è¯•è¡¨ç°è‰¯å¥½ï¼Œåœ¨æŸäº›é¢†åŸŸæœ‰çªå‡ºè¡¨ç°")
    else:
        insights['performance_insights'].append("é¢è¯•è¡¨ç°æœ‰è¾ƒå¤§æå‡ç©ºé—´ï¼Œå»ºè®®é‡ç‚¹å…³æ³¨åŸºç¡€æŠ€èƒ½")
    
    # è¡Œä¸ºæ¨¡å¼åˆ†æ
    if answer_analysis:
        avg_response_time = sum(a.get('response_time_seconds', 0) for a in answer_analysis) / len(answer_analysis)
        if avg_response_time < 120:
            insights['behavioral_patterns'].append("å›ç­”é€Ÿåº¦è¾ƒå¿«ï¼Œæ€ç»´æ•æ·")
        elif avg_response_time > 300:
            insights['behavioral_patterns'].append("æ€è€ƒæ—¶é—´è¾ƒé•¿ï¼Œåå‘æ·±åº¦æ€è€ƒ")
        
        # ç­”æ¡ˆé•¿åº¦åˆ†æ
        avg_word_count = sum(a.get('word_count', 0) for a in answer_analysis) / len(answer_analysis)
        if avg_word_count > 80:
            insights['behavioral_patterns'].append("å›ç­”è¯¦ç»†å……å®ï¼Œå–„äºè¡¨è¾¾")
        elif avg_word_count < 30:
            insights['behavioral_patterns'].append("å›ç­”è¾ƒä¸ºç®€æ´ï¼Œå¯é€‚å½“å¢åŠ ç»†èŠ‚")
    
    # æŠ€æœ¯è¯„ä¼°
    tech_scores = []
    for analysis in answer_analysis:
        if analysis.get('question_type') == 'technical':
            tech_scores.append(analysis.get('technical_score', 0))
    
    if tech_scores:
        insights['technical_assessment'] = {
            'average_score': round(sum(tech_scores) / len(tech_scores), 1),
            'consistency': len([s for s in tech_scores if abs(s - sum(tech_scores)/len(tech_scores)) < 10]) / len(tech_scores),
            'strength_areas': _identify_technical_strengths(answer_analysis),
            'improvement_areas': _identify_technical_weaknesses(answer_analysis)
        }
    
    return insights


def _format_export_data(analysis_result, export_format):
    """æ ¼å¼åŒ–å¯¼å‡ºæ•°æ®"""
    export_data = {
        'metadata': {
            'export_format': export_format,
            'export_date': datetime.utcnow().isoformat(),
            'session_id': analysis_result['session_info']['session_id']
        },
        'summary': {
            'overall_score': analysis_result['overall_score'],
            'session_info': analysis_result['session_info'],
            'performance_metrics': analysis_result['performance_metrics']
        },
        'detailed_results': {
            'section_scores': analysis_result['section_scores'],
            'answer_analysis': analysis_result['answer_analysis'],
            'strengths': analysis_result['strengths'],
            'weaknesses': analysis_result['weaknesses'],
            'recommendations': analysis_result['recommendations']
        }
    }
    
    if export_format == 'csv':
        # ä¸ºCSVæ ¼å¼å‡†å¤‡å¹³é“ºæ•°æ®
        export_data['csv_data'] = _flatten_for_csv(analysis_result)
    
    return export_data


# è¾…åŠ©å‡½æ•°
def _get_performance_grade(score):
    """è·å–è¡¨ç°ç­‰çº§"""
    if score >= 90:
        return 'A+'
    elif score >= 85:
        return 'A'
    elif score >= 80:
        return 'A-'
    elif score >= 75:
        return 'B+'
    elif score >= 70:
        return 'B'
    elif score >= 65:
        return 'B-'
    elif score >= 60:
        return 'C+'
    elif score >= 55:
        return 'C'
    else:
        return 'D'


def _calculate_percentile(score):
    """è®¡ç®—ç™¾åˆ†ä½æ’åï¼ˆæ¨¡æ‹Ÿï¼‰"""
    # ç®€åŒ–ç‰ˆç™¾åˆ†ä½è®¡ç®—
    if score >= 90:
        return 95
    elif score >= 80:
        return 85
    elif score >= 70:
        return 70
    elif score >= 60:
        return 50
    else:
        return 25


def _identify_technical_strengths(answer_analysis):
    """è¯†åˆ«æŠ€æœ¯ä¼˜åŠ¿"""
    strengths = []
    for analysis in answer_analysis:
        if (analysis.get('question_type') == 'technical' and 
            analysis.get('technical_score', 0) > 80):
            keywords = analysis.get('keywords_found', {})
            for category, words in keywords.items():
                if words:
                    strengths.extend(words[:2])  # å–å‰ä¸¤ä¸ªå…³é”®è¯
    return list(set(strengths))[:5]


def _identify_technical_weaknesses(answer_analysis):
    """è¯†åˆ«æŠ€æœ¯å¼±ç‚¹"""
    weaknesses = []
    for analysis in answer_analysis:
        if (analysis.get('question_type') == 'technical' and 
            analysis.get('technical_score', 0) < 60):
            # åŸºäºç¼ºä¹çš„æŠ€æœ¯å…³é”®è¯è¯†åˆ«å¼±ç‚¹
            if analysis.get('word_count', 0) < 50:
                weaknesses.append("å›ç­”æ·±åº¦ä¸è¶³")
            if not analysis.get('keywords_found', {}):
                weaknesses.append("æŠ€æœ¯è¯æ±‡ä½¿ç”¨è¾ƒå°‘")
    return list(set(weaknesses))[:3]


def _flatten_for_csv(analysis_result):
    """ä¸ºCSVå¯¼å‡ºå¹³é“ºæ•°æ®"""
    flattened = []
    
    # åŸºç¡€ä¿¡æ¯
    session_info = analysis_result['session_info']
    base_row = {
        'session_id': session_info['session_id'],
        'interview_type': session_info['interview_type'],
        'title': session_info['title'],
        'overall_score': analysis_result['overall_score'],
        'completion_rate': analysis_result['performance_metrics']['completion_rate']
    }
    
    # æ¯ä¸ªç­”æ¡ˆä¸€è¡Œ
    for analysis in analysis_result.get('answer_analysis', []):
        row = base_row.copy()
        row.update({
            'question_id': analysis['question_id'],
            'question_type': analysis['question_type'],
            'question_difficulty': analysis['question_difficulty'],
            'answer_score': analysis['total_score'],
            'response_time': analysis['response_time_seconds'],
            'word_count': analysis['word_count']
        })
        flattened.append(row)
    
    return flattened 