#!/usr/bin/env python3
import os
import sys
import re
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__)))

from app.services.resume_parser import ResumeParser

def debug_resume_parsing(file_path):
    """è°ƒè¯•ç®€å†è§£æè¿‡ç¨‹"""
    print(f"ğŸ” å¼€å§‹è°ƒè¯•ç®€å†æ–‡ä»¶: {file_path}")
    print("=" * 60)
    
    if not os.path.exists(file_path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return
    
    # è·å–æ–‡ä»¶ç±»å‹
    file_type = Path(file_path).suffix.lower().lstrip('.')
    print(f"ğŸ“„ æ–‡ä»¶ç±»å‹: {file_type}")
    
    # åˆ›å»ºè§£æå™¨
    parser = ResumeParser()
    
    try:
        # 1. æå–åŸå§‹æ–‡æœ¬
        print("\nğŸ“ æ­¥éª¤1: æå–åŸå§‹æ–‡æœ¬")
        raw_text = parser._extract_text(file_path, file_type)
        print(f"âœ… æå–æˆåŠŸï¼Œæ–‡æœ¬é•¿åº¦: {len(raw_text)} å­—ç¬¦")
        
        # æ˜¾ç¤ºå‰500å­—ç¬¦
        print("\nğŸ“– åŸå§‹æ–‡æœ¬é¢„è§ˆ (å‰500å­—ç¬¦):")
        print("-" * 40)
        print(repr(raw_text[:500]))
        print("-" * 40)
        
        # 2. æ£€æŸ¥å·¥ä½œç»å†éƒ¨åˆ†
        print("\nğŸ” æ­¥éª¤2: åˆ†æå·¥ä½œç»å†éƒ¨åˆ†")
        
        # æŸ¥æ‰¾æ‰€æœ‰å¯èƒ½çš„å·¥ä½œç»å†æ ‡é¢˜
        experience_patterns = [
            r'work\s*experience',
            r'professional\s*experience', 
            r'employment\s*history',
            r'career\s*history',
            r'experience',
            r'employment',
            r'å·¥ä½œç»å†',
            r'å·¥ä½œç»éªŒ',
            r'èŒä¸šç»å†'
        ]
        
        found_sections = []
        for pattern in experience_patterns:
            matches = re.finditer(pattern, raw_text, re.IGNORECASE)
            for match in matches:
                start = max(0, match.start() - 50)
                end = min(len(raw_text), match.end() + 200)
                context = raw_text[start:end]
                found_sections.append({
                    'pattern': pattern,
                    'position': match.start(),
                    'context': context
                })
        
        if found_sections:
            print(f"âœ… æ‰¾åˆ° {len(found_sections)} ä¸ªå¯èƒ½çš„å·¥ä½œç»å†æ ‡é¢˜:")
            for i, section in enumerate(found_sections):
                print(f"\næ ‡é¢˜ {i+1}: æ¨¡å¼ '{section['pattern']}' (ä½ç½®: {section['position']})")
                print("ä¸Šä¸‹æ–‡:")
                print(repr(section['context']))
        else:
            print("âŒ æœªæ‰¾åˆ°å·¥ä½œç»å†æ ‡é¢˜")
        
        # 3. ä½¿ç”¨ç°æœ‰é€»è¾‘æå–å·¥ä½œç»å†
        print("\nğŸ”§ æ­¥éª¤3: ä½¿ç”¨ç°æœ‰é€»è¾‘æå–")
        experiences = parser._extract_experience(raw_text)
        print(f"ğŸ“Š æå–ç»“æœ: {len(experiences)} ä¸ªå·¥ä½œç»å†")
        
        for i, exp in enumerate(experiences):
            print(f"\nå·¥ä½œç»å† {i+1}:")
            print(f"  å…¬å¸: {exp.get('company', 'æœªçŸ¥')}")
            print(f"  èŒä½: {exp.get('position', 'æœªçŸ¥')}")
            print(f"  æ—¶é—´: {exp.get('duration', 'æœªçŸ¥')}")
            print(f"  åŸå§‹æ–‡æœ¬: {exp.get('raw_text', '')[:100]}...")
        
        # 4. å°è¯•æ”¹è¿›çš„æå–é€»è¾‘
        print("\nğŸš€ æ­¥éª¤4: å°è¯•æ”¹è¿›çš„æå–é€»è¾‘")
        improved_experiences = extract_experience_improved(raw_text)
        print(f"ğŸ“Š æ”¹è¿›æå–ç»“æœ: {len(improved_experiences)} ä¸ªå·¥ä½œç»å†")
        
        for i, exp in enumerate(improved_experiences):
            print(f"\næ”¹è¿›ç»“æœ {i+1}:")
            print(f"  å…¬å¸: {exp.get('company', 'æœªçŸ¥')}")
            print(f"  èŒä½: {exp.get('position', 'æœªçŸ¥')}")
            print(f"  æ—¶é—´: {exp.get('duration', 'æœªçŸ¥')}")
            print(f"  åŸå§‹æ–‡æœ¬: {exp.get('raw_text', '')[:100]}...")
        
        # 5. å®Œæ•´è§£ææµ‹è¯•
        print("\nğŸ“‹ æ­¥éª¤5: å®Œæ•´è§£ææµ‹è¯•")
        result = parser.parse_resume(file_path, file_type)
        
        if result['success']:
            parsed_data = result['parsed_data']
            print("âœ… è§£ææˆåŠŸ!")
            print(f"  å§“å: {parsed_data.get('name', 'æœªè¯†åˆ«')}")
            print(f"  é‚®ç®±: {parsed_data.get('email', 'æœªè¯†åˆ«')}")
            print(f"  ç”µè¯: {parsed_data.get('phone', 'æœªè¯†åˆ«')}")
            print(f"  æŠ€èƒ½æ•°é‡: {len(parsed_data.get('skills', []))}")
            print(f"  å·¥ä½œç»å†æ•°é‡: {len(parsed_data.get('experience', []))}")
            print(f"  æ•™è‚²èƒŒæ™¯æ•°é‡: {len(parsed_data.get('education', []))}")
        else:
            print(f"âŒ è§£æå¤±è´¥: {result['error']}")
        
    except Exception as e:
        print(f"âŒ è°ƒè¯•è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
        import traceback
        traceback.print_exc()

def extract_experience_improved(text: str) -> list:
    """æ”¹è¿›çš„å·¥ä½œç»å†æå–é€»è¾‘"""
    experiences = []
    
    # æ›´çµæ´»çš„å·¥ä½œç»å†æ ‡é¢˜åŒ¹é…
    exp_pattern = r'(?:work\s*experience|professional\s*experience|employment\s*history|career\s*history|experience|employment|å·¥ä½œç»å†|å·¥ä½œç»éªŒ|èŒä¸šç»å†)[:\s]*'
    
    # æŸ¥æ‰¾å·¥ä½œç»å†éƒ¨åˆ†
    exp_matches = list(re.finditer(exp_pattern, text, re.IGNORECASE))
    
    for match in exp_matches:
        start_pos = match.end()
        
        # æŸ¥æ‰¾ä¸‹ä¸€ä¸ªä¸»è¦éƒ¨åˆ†çš„å¼€å§‹
        next_section_pattern = r'\n\s*(?:education|skills|æŠ€èƒ½|æ•™è‚²|projects|é¡¹ç›®|certifications|è¯ä¹¦|references|æ¨è)'
        next_match = re.search(next_section_pattern, text[start_pos:], re.IGNORECASE)
        
        if next_match:
            end_pos = start_pos + next_match.start()
        else:
            end_pos = len(text)
        
        # æå–è¿™ä¸€éƒ¨åˆ†çš„æ–‡æœ¬
        section_text = text[start_pos:end_pos].strip()
        
        if section_text:
            print(f"ğŸ” æ‰¾åˆ°å·¥ä½œç»å†éƒ¨åˆ† (é•¿åº¦: {len(section_text)}):")
            print("-" * 30)
            print(section_text[:300] + "..." if len(section_text) > 300 else section_text)
            print("-" * 30)
            
            # å°è¯•åˆ†å‰²å·¥ä½œç»å†æ¡ç›®
            # æŒ‰ç©ºè¡Œåˆ†å‰²
            jobs = re.split(r'\n\s*\n', section_text)
            
            for job in jobs:
                job = job.strip()
                if job and len(job) > 20:  # è¿‡æ»¤å¤ªçŸ­çš„æ–‡æœ¬
                    experiences.append({
                        'raw_text': job,
                        'company': extract_company_improved(job),
                        'position': extract_position_improved(job),
                        'duration': extract_duration_improved(job)
                    })
    
    return experiences

def extract_company_improved(text: str) -> str:
    """æ”¹è¿›çš„å…¬å¸åæå–"""
    # å¸¸è§çš„å…¬å¸åæ¨¡å¼
    patterns = [
        r'(?:at\s+|@\s*)([A-Z][A-Za-z\s&.,]+?)(?:\s*[,\n]|\s*$)',
        r'^([A-Z][A-Za-z\s&.,]+?)(?:\s*[,\n]|\s+\d{4})',
        r'([A-Z][A-Za-z\s&.,]+?)\s*(?:Inc|Corp|Ltd|LLC|Co)'
    ]
    
    for pattern in patterns:
        match = re.search(pattern, text)
        if match:
            company = match.group(1).strip()
            if len(company) > 2 and len(company) < 50:
                return company
    
    return None

def extract_position_improved(text: str) -> str:
    """æ”¹è¿›çš„èŒä½æå–"""
    lines = text.split('\n')
    for line in lines[:3]:  # æ£€æŸ¥å‰å‡ è¡Œ
        line = line.strip()
        if line and not re.search(r'\d{4}', line):  # ä¸åŒ…å«å¹´ä»½çš„è¡Œ
            # ç§»é™¤å…¬å¸åç­‰ä¿¡æ¯
            cleaned = re.sub(r'\s*(?:at\s+|@\s*)[A-Z].*', '', line)
            if cleaned and len(cleaned) > 3 and len(cleaned) < 100:
                return cleaned.strip()
    return None

def extract_duration_improved(text: str) -> str:
    """æ”¹è¿›çš„æ—¶é—´æ®µæå–"""
    # åŒ¹é…å„ç§æ—¶é—´æ ¼å¼
    patterns = [
        r'(\d{4})\s*[-â€“â€”]\s*(\d{4})',
        r'(\d{4})\s*[-â€“â€”]\s*present',
        r'(\w+\s+\d{4})\s*[-â€“â€”]\s*(\w+\s+\d{4})',
        r'(\w+\s+\d{4})\s*[-â€“â€”]\s*present'
    ]
    
    for pattern in patterns:
        match = re.search(pattern, text, re.IGNORECASE)
        if match:
            return match.group(0)
    
    return None

if __name__ == "__main__":
    # ä½¿ç”¨ç”¨æˆ·æä¾›çš„æ–‡ä»¶è·¯å¾„
    file_path = "/Users/mayuyang/InterviewPro/temp/resume.doc"
    debug_resume_parsing(file_path) 