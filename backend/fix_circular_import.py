#!/usr/bin/env python3
"""
ä¿®å¤å¾ªç¯å¯¼å…¥é—®é¢˜
"""

import os

# ä¿®å¤ä»»åŠ¡æ–‡ä»¶
tasks_content = '''#!/usr/bin/env python3
"""
é—®é¢˜ç”Ÿæˆå¼‚æ­¥ä»»åŠ¡
å¤„ç†è€—æ—¶çš„AIé—®é¢˜ç”Ÿæˆå’ŒAIå‚è€ƒç­”æ¡ˆç”Ÿæˆ
"""
import json
import logging
from celery import current_task
from celery.utils.log import get_task_logger
from datetime import datetime

from app.services.ai_question_generator import AIQuestionGenerator
from app.services.question_cache_service import QuestionCacheService
from app.models.resume import Resume
from app.models.question import InterviewType
from app.extensions import get_redis_client

logger = get_task_logger(__name__)

# å»¶è¿Ÿå¯¼å…¥Celeryï¼Œé¿å…å¾ªç¯å¯¼å…¥
def get_celery_app():
    from app import create_app
    return create_app().celery

celery = get_celery_app()

@celery.task(bind=True)
def generate_questions_async(self, resume_data, user_id, interview_type, total_questions, 
                           difficulty_distribution=None, type_distribution=None):
    """
    å¼‚æ­¥ç”Ÿæˆé¢è¯•é—®é¢˜
    
    Args:
        resume_data: ç®€å†æ•°æ®å­—å…¸
        user_id: ç”¨æˆ·ID
        interview_type: é¢è¯•ç±»å‹
        total_questions: é—®é¢˜æ€»æ•°
        difficulty_distribution: éš¾åº¦åˆ†å¸ƒ
        type_distribution: ç±»å‹åˆ†å¸ƒ
    
    Returns:
        dict: åŒ…å«ä»»åŠ¡çŠ¶æ€å’Œç»“æœ
    """
    try:
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€
        self.update_state(
            state='PROGRESS',
            meta={
                'current': 0,
                'total': 100,
                'status': 'å¼€å§‹ç”Ÿæˆé—®é¢˜...'
            }
        )
        
        # åˆ›å»ºç®€å†å¯¹è±¡
        resume = Resume(
            id=resume_data.get('id'),
            user_id=user_id,
            filename=resume_data.get('filename', ''),
            content=resume_data.get('content', ''),
            parsed_data=resume_data.get('parsed_data', {}),
            created_at=datetime.now()
        )
        
        # æ›´æ–°è¿›åº¦
        self.update_state(
            state='PROGRESS',
            meta={
                'current': 20,
                'total': 100,
                'status': 'åˆå§‹åŒ–AIç”Ÿæˆå™¨...'
            }
        )
        
        # åˆå§‹åŒ–AIç”Ÿæˆå™¨å’Œç¼“å­˜æœåŠ¡
        ai_generator = AIQuestionGenerator()
        cache_service = QuestionCacheService()
        
        # æ›´æ–°è¿›åº¦
        self.update_state(
            state='PROGRESS',
            meta={
                'current': 40,
                'total': 100,
                'status': 'æ£€æŸ¥ç¼“å­˜...'
            }
        )
        
        # æ£€æŸ¥ç¼“å­˜
        cached_questions = cache_service.get_cached_questions(
            user_id=user_id,
            resume=resume,
            interview_type=interview_type,
            total_questions=total_questions,
            difficulty_distribution=difficulty_distribution or {"easy": 2, "medium": 2, "hard": 1},
            type_distribution=type_distribution or {"technical": 3, "behavioral": 2}
        )
        
        if cached_questions:
            logger.info(f"âœ… ç”¨æˆ·{user_id}ä»ç¼“å­˜è·å–åˆ° {len(cached_questions)} ä¸ªé—®é¢˜")
            self.update_state(
                state='PROGRESS',
                meta={
                    'current': 100,
                    'total': 100,
                    'status': 'ä»ç¼“å­˜è·å–é—®é¢˜å®Œæˆ'
                }
            )
            return {
                'status': 'SUCCESS',
                'questions': cached_questions,
                'from_cache': True,
                'generated_at': datetime.now().isoformat()
            }
        
        # æ›´æ–°è¿›åº¦
        self.update_state(
            state='PROGRESS',
            meta={
                'current': 60,
                'total': 100,
                'status': 'è°ƒç”¨AIç”Ÿæˆé—®é¢˜...'
            }
        )
        
        # ç”Ÿæˆé—®é¢˜
        questions = ai_generator.generate_questions_for_resume(
            resume=resume,
            user_id=user_id,
            interview_type=InterviewType(interview_type),
            total_questions=total_questions,
            difficulty_distribution=difficulty_distribution,
            type_distribution=type_distribution
        )
        
        # æ›´æ–°è¿›åº¦
        self.update_state(
            state='PROGRESS',
            meta={
                'current': 90,
                'total': 100,
                'status': 'ç¼“å­˜ç”Ÿæˆçš„é—®é¢˜...'
            }
        )
        
        # ç¼“å­˜é—®é¢˜
        cache_service.cache_questions(
            user_id=user_id,
            resume=resume,
            interview_type=interview_type,
            total_questions=total_questions,
            difficulty_distribution=difficulty_distribution or {"easy": 2, "medium": 2, "hard": 1},
            type_distribution=type_distribution or {"technical": 3, "behavioral": 2},
            questions=questions
        )
        
        # å®Œæˆ
        self.update_state(
            state='PROGRESS',
            meta={
                'current': 100,
                'total': 100,
                'status': 'é—®é¢˜ç”Ÿæˆå®Œæˆ'
            }
        )
        
        logger.info(f"âœ… ç”¨æˆ·{user_id}å¼‚æ­¥ç”Ÿæˆå®Œæˆ {len(questions)} ä¸ªé—®é¢˜")
        
        return {
            'status': 'SUCCESS',
            'questions': questions,
            'from_cache': False,
            'generated_at': datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"âŒ å¼‚æ­¥é—®é¢˜ç”Ÿæˆå¤±è´¥: {str(e)}")
        return {
            'status': 'FAILURE',
            'error': str(e),
            'generated_at': datetime.now().isoformat()
        }

@celery.task(bind=True)
def generate_ai_reference_async(self, question_text, user_answer, job_title=None):
    """
    å¼‚æ­¥ç”ŸæˆAIå‚è€ƒç­”æ¡ˆ
    
    Args:
        question_text: é—®é¢˜æ–‡æœ¬
        user_answer: ç”¨æˆ·ç­”æ¡ˆ
        job_title: èŒä½æ ‡é¢˜
    
    Returns:
        dict: åŒ…å«AIå‚è€ƒç­”æ¡ˆ
    """
    try:
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€
        self.update_state(
            state='PROGRESS',
            meta={
                'current': 0,
                'total': 100,
                'status': 'å¼€å§‹ç”ŸæˆAIå‚è€ƒç­”æ¡ˆ...'
            }
        )
        
        # åˆå§‹åŒ–AIç”Ÿæˆå™¨
        ai_generator = AIQuestionGenerator()
        
        # æ›´æ–°è¿›åº¦
        self.update_state(
            state='PROGRESS',
            meta={
                'current': 50,
                'total': 100,
                'status': 'è°ƒç”¨AIç”Ÿæˆå‚è€ƒç­”æ¡ˆ...'
            }
        )
        
        # ç”ŸæˆAIå‚è€ƒç­”æ¡ˆ
        ai_reference = ai_generator.generate_ai_reference_answer(
            question_text=question_text,
            user_answer=user_answer,
            job_title=job_title
        )
        
        # å®Œæˆ
        self.update_state(
            state='PROGRESS',
            meta={
                'current': 100,
                'total': 100,
                'status': 'AIå‚è€ƒç­”æ¡ˆç”Ÿæˆå®Œæˆ'
            }
        )
        
        logger.info(f"âœ… AIå‚è€ƒç­”æ¡ˆç”Ÿæˆå®Œæˆ")
        
        return {
            'status': 'SUCCESS',
            'ai_reference': ai_reference,
            'generated_at': datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"âŒ AIå‚è€ƒç­”æ¡ˆç”Ÿæˆå¤±è´¥: {str(e)}")
        return {
            'status': 'FAILURE',
            'error': str(e),
            'generated_at': datetime.now().isoformat()
        }
'''

# å†™å…¥ä¿®å¤åçš„ä»»åŠ¡æ–‡ä»¶
with open('app/tasks/question_tasks.py', 'w', encoding='utf-8') as f:
    f.write(tasks_content)

print("âœ… å·²ä¿®å¤ question_tasks.py çš„å¾ªç¯å¯¼å…¥é—®é¢˜")

# éªŒè¯ä¿®å¤ç»“æœ
print("ğŸ” éªŒè¯ä¿®å¤ç»“æœ...")
try:
    # æµ‹è¯•å¯¼å…¥
    from app.api.questions import questions_bp
    print("âœ… APIæ–‡ä»¶å¯¼å…¥æˆåŠŸ")
    
    # æµ‹è¯•ä»»åŠ¡æ–‡ä»¶
    from app.tasks.question_tasks import generate_questions_async, generate_ai_reference_async
    print("âœ… ä»»åŠ¡æ–‡ä»¶å¯¼å…¥æˆåŠŸ")
    
    print("ğŸ‰ å¾ªç¯å¯¼å…¥é—®é¢˜ä¿®å¤å®Œæˆï¼")
    
except Exception as e:
    print(f"âŒ ä¿®å¤éªŒè¯å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()
