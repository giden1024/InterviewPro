# InterviewGenius AI è¿ç»´éƒ¨ç½²æ–‡æ¡£

## 1. å®¹å™¨åŒ–éƒ¨ç½²

### 1.1 Dockeræ¶æ„è®¾è®¡
```
å®¹å™¨åŒ–æ¶æ„
â”œâ”€â”€ å‰ç«¯å®¹å™¨ (nginx:alpine)
â”‚   â”œâ”€â”€ Reactåº”ç”¨æ‰“åŒ…
â”‚   â”œâ”€â”€ Nginxé…ç½®
â”‚   â””â”€â”€ é™æ€èµ„æºæœåŠ¡
â”œâ”€â”€ åç«¯å®¹å™¨ (python:3.11-slim)
â”‚   â”œâ”€â”€ Flaskåº”ç”¨
â”‚   â”œâ”€â”€ GunicornæœåŠ¡å™¨
â”‚   â””â”€â”€ Pythonä¾èµ–
â”œâ”€â”€ æ•°æ®åº“å®¹å™¨ (mysql:8.0)
â”‚   â”œâ”€â”€ MySQLæ•°æ®åº“
â”‚   â”œâ”€â”€ æ•°æ®æŒä¹…åŒ–
â”‚   â””â”€â”€ é…ç½®ä¼˜åŒ–
â”œâ”€â”€ ç¼“å­˜å®¹å™¨ (redis:7-alpine)
â”‚   â”œâ”€â”€ Redisç¼“å­˜
â”‚   â”œâ”€â”€ ä¼šè¯å­˜å‚¨
â”‚   â””â”€â”€ æ¶ˆæ¯é˜Ÿåˆ—
â””â”€â”€ åå‘ä»£ç† (nginx)
    â”œâ”€â”€ è´Ÿè½½å‡è¡¡
    â”œâ”€â”€ SSLç»ˆæ­¢
    â””â”€â”€ é™æ€æ–‡ä»¶æœåŠ¡
```

### 1.2 Dockerfileé…ç½®

#### 1.2.1 å‰ç«¯Dockerfile
```dockerfile
# frontend/Dockerfile
FROM node:18-alpine AS builder

WORKDIR /app

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY package*.json ./
RUN npm ci --only=production

# å¤åˆ¶æºä»£ç 
COPY . .

# æ„å»ºåº”ç”¨
RUN npm run build

# ç”Ÿäº§ç¯å¢ƒé•œåƒ
FROM nginx:alpine

# å¤åˆ¶æ„å»ºäº§ç‰©
COPY --from=builder /app/dist /usr/share/nginx/html

# å¤åˆ¶nginxé…ç½®
COPY nginx.conf /etc/nginx/conf.d/default.conf

# æš´éœ²ç«¯å£
EXPOSE 80

# å¯åŠ¨nginx
CMD ["nginx", "-g", "daemon off;"]
```

#### 1.2.2 åç«¯Dockerfile
```dockerfile
# backend/Dockerfile
FROM python:3.11-slim

WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    libffi-dev \
    libssl-dev \
    && rm -rf /var/lib/apt/lists/*

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY . .

# åˆ›å»ºérootç”¨æˆ·
RUN useradd --create-home --shell /bin/bash app \
    && chown -R app:app /app
USER app

# æš´éœ²ç«¯å£
EXPOSE 5000

# å¯åŠ¨åº”ç”¨
CMD ["gunicorn", "--bind", "0.0.0.0:5000", "--workers", "4", "app:app"]
```

### 1.3 Docker Composeé…ç½®
```yaml
# docker-compose.yml
version: '3.8'

services:
  # å‰ç«¯æœåŠ¡
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "3000:80"
    depends_on:
      - backend
    environment:
      - REACT_APP_API_URL=http://backend:5000
    networks:
      - app-network

  # åç«¯æœåŠ¡
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    ports:
      - "5000:5000"
    depends_on:
      - mysql
      - redis
    environment:
      - DATABASE_URL=mysql+pymysql://interview:password@mysql:3306/interview_db
      - REDIS_URL=redis://redis:6379/0
      - FLASK_ENV=production
      - SECRET_KEY=${SECRET_KEY}
      - JWT_SECRET_KEY=${JWT_SECRET_KEY}
    volumes:
      - ./uploads:/app/uploads
    networks:
      - app-network
    restart: unless-stopped

  # æ•°æ®åº“æœåŠ¡
  mysql:
    image: mysql:8.0
    environment:
      - MYSQL_ROOT_PASSWORD=${MYSQL_ROOT_PASSWORD}
      - MYSQL_DATABASE=interview_db
      - MYSQL_USER=interview
      - MYSQL_PASSWORD=${MYSQL_PASSWORD}
    volumes:
      - mysql_data:/var/lib/mysql
      - ./database/init.sql:/docker-entrypoint-initdb.d/init.sql
    ports:
      - "3306:3306"
    networks:
      - app-network
    restart: unless-stopped

  # ç¼“å­˜æœåŠ¡
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - app-network
    restart: unless-stopped

  # åå‘ä»£ç†
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./nginx/ssl:/etc/nginx/ssl
      - ./uploads:/var/www/uploads
    depends_on:
      - frontend
      - backend
    networks:
      - app-network
    restart: unless-stopped

  # ç›‘æ§æœåŠ¡
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    networks:
      - app-network

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
    volumes:
      - grafana_data:/var/lib/grafana
    networks:
      - app-network

volumes:
  mysql_data:
  redis_data:
  prometheus_data:
  grafana_data:

networks:
  app-network:
    driver: bridge
```

## 2. Nginxé…ç½®

### 2.1 ä¸»é…ç½®æ–‡ä»¶
```nginx
# nginx/nginx.conf
user nginx;
worker_processes auto;
error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;

events {
    worker_connections 1024;
    use epoll;
    multi_accept on;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    # æ—¥å¿—æ ¼å¼
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for"';

    access_log /var/log/nginx/access.log main;

    # æ€§èƒ½ä¼˜åŒ–
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;

    # Gzipå‹ç¼©
    gzip on;
    gzip_vary on;
    gzip_min_length 10240;
    gzip_proxied expired no-cache no-store private must-revalidate;
    gzip_types
        text/plain
        text/css
        text/xml
        text/javascript
        application/x-javascript
        application/xml+rss
        application/javascript
        application/json;

    # å®‰å…¨å¤´
    add_header X-Frame-Options DENY;
    add_header X-Content-Type-Options nosniff;
    add_header X-XSS-Protection "1; mode=block";
    add_header Strict-Transport-Security "max-age=31536000; includeSubDomains";

    # ä¸Šæ¸¸æœåŠ¡å™¨
    upstream backend_servers {
        least_conn;
        server backend:5000 max_fails=3 fail_timeout=30s;
        keepalive 32;
    }

    upstream frontend_servers {
        least_conn;
        server frontend:80 max_fails=3 fail_timeout=30s;
        keepalive 32;
    }

    # é™æµé…ç½®
    limit_req_zone $binary_remote_addr zone=api:10m rate=10r/s;
    limit_req_zone $binary_remote_addr zone=login:10m rate=5r/m;

    # ä¸»æœåŠ¡å™¨é…ç½®
    server {
        listen 80;
        server_name interview-genius.com www.interview-genius.com;
        
        # HTTPé‡å®šå‘åˆ°HTTPS
        return 301 https://$server_name$request_uri;
    }

    server {
        listen 443 ssl http2;
        server_name interview-genius.com www.interview-genius.com;

        # SSLé…ç½®
        ssl_certificate /etc/nginx/ssl/fullchain.pem;
        ssl_certificate_key /etc/nginx/ssl/privkey.pem;
        ssl_protocols TLSv1.2 TLSv1.3;
        ssl_ciphers ECDHE-RSA-AES256-GCM-SHA512:DHE-RSA-AES256-GCM-SHA512:ECDHE-RSA-AES256-GCM-SHA384;
        ssl_prefer_server_ciphers off;
        ssl_session_cache shared:SSL:10m;
        ssl_session_timeout 10m;

        # å®¢æˆ·ç«¯æœ€å¤§ä¸Šä¼ å¤§å°
        client_max_body_size 100M;

        # å‰ç«¯é™æ€æ–‡ä»¶
        location / {
            proxy_pass http://frontend_servers;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            # ç¼“å­˜é™æ€èµ„æº
            location ~* \.(js|css|png|jpg|jpeg|gif|ico|svg|woff|woff2|ttf|eot)$ {
                expires 1y;
                add_header Cache-Control "public, immutable";
            }
        }

        # APIæ¥å£
        location /api/ {
            limit_req zone=api burst=20 nodelay;
            
            proxy_pass http://backend_servers;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            # WebSocketæ”¯æŒ
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection "upgrade";
            
            # è¶…æ—¶é…ç½®
            proxy_connect_timeout 60s;
            proxy_send_timeout 60s;
            proxy_read_timeout 60s;
        }

        # ç™»å½•æ¥å£ç‰¹æ®Šé™æµ
        location /api/auth/login {
            limit_req zone=login burst=5 nodelay;
            
            proxy_pass http://backend_servers;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }

        # WebSocketè¿æ¥
        location /ws/ {
            proxy_pass http://backend_servers;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection "upgrade";
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            # WebSocketè¶…æ—¶
            proxy_read_timeout 3600s;
            proxy_send_timeout 3600s;
        }

        # æ–‡ä»¶ä¸Šä¼ /ä¸‹è½½
        location /uploads/ {
            alias /var/www/uploads/;
            expires 1d;
            add_header Cache-Control "public";
            
            # å®‰å…¨æ£€æŸ¥
            location ~* \.(php|jsp|asp|sh|pl|py)$ {
                deny all;
            }
        }

        # å¥åº·æ£€æŸ¥
        location /health {
            access_log off;
            return 200 "healthy\n";
            add_header Content-Type text/plain;
        }

        # ç›‘æ§ç«¯ç‚¹
        location /metrics {
            proxy_pass http://backend_servers/metrics;
            allow 127.0.0.1;
            deny all;
        }
    }
}
```

## 3. CI/CDæµç¨‹

### 3.1 GitHub Actionsé…ç½®
```yaml
# .github/workflows/deploy.yml
name: Deploy to Production

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  test:
    runs-on: ubuntu-latest
    
    services:
      mysql:
        image: mysql:8.0
        env:
          MYSQL_ROOT_PASSWORD: test
          MYSQL_DATABASE: test_db
        options: >-
          --health-cmd="mysqladmin ping"
          --health-interval=10s
          --health-timeout=5s
          --health-retries=3
        ports:
          - 3306:3306

      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd="redis-cli ping"
          --health-interval=10s
          --health-timeout=5s
          --health-retries=3
        ports:
          - 6379:6379

    steps:
    - uses: actions/checkout@v3

    - name: Set up Node.js
      uses: actions/setup-node@v3
      with:
        node-version: '18'
        cache: 'npm'
        cache-dependency-path: frontend/package-lock.json

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install frontend dependencies
      run: |
        cd frontend
        npm ci

    - name: Install backend dependencies
      run: |
        cd backend
        pip install -r requirements.txt

    - name: Run frontend tests
      run: |
        cd frontend
        npm run test:ci

    - name: Run backend tests
      run: |
        cd backend
        python -m pytest tests/ -v --cov=./ --cov-report=xml
      env:
        DATABASE_URL: mysql+pymysql://root:test@localhost:3306/test_db
        REDIS_URL: redis://localhost:6379/0

    - name: Upload coverage reports
      uses: codecov/codecov-action@v3
      with:
        file: ./backend/coverage.xml
        fail_ci_if_error: true

  build:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'

    steps:
    - uses: actions/checkout@v3

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v2

    - name: Log in to Container Registry
      uses: docker/login-action@v2
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}

    - name: Extract metadata (tags, labels)
      id: meta-frontend
      uses: docker/metadata-action@v4
      with:
        images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}-frontend

    - name: Extract metadata (tags, labels)
      id: meta-backend
      uses: docker/metadata-action@v4
      with:
        images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}-backend

    - name: Build and push frontend image
      uses: docker/build-push-action@v4
      with:
        context: ./frontend
        push: true
        tags: ${{ steps.meta-frontend.outputs.tags }}
        labels: ${{ steps.meta-frontend.outputs.labels }}
        cache-from: type=gha
        cache-to: type=gha,mode=max

    - name: Build and push backend image
      uses: docker/build-push-action@v4
      with:
        context: ./backend
        push: true
        tags: ${{ steps.meta-backend.outputs.tags }}
        labels: ${{ steps.meta-backend.outputs.labels }}
        cache-from: type=gha
        cache-to: type=gha,mode=max

  deploy:
    needs: build
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'

    steps:
    - uses: actions/checkout@v3

    - name: Deploy to production
      uses: appleboy/ssh-action@v0.1.7
      with:
        host: ${{ secrets.PROD_HOST }}
        username: ${{ secrets.PROD_USER }}
        key: ${{ secrets.PROD_SSH_KEY }}
        script: |
          cd /opt/interview-genius
          
          # æ›´æ–°ä»£ç 
          git pull origin main
          
          # æ›´æ–°é•œåƒ
          docker-compose pull
          
          # æ»šåŠ¨æ›´æ–°
          docker-compose up -d --remove-orphans
          
          # å¥åº·æ£€æŸ¥
          sleep 30
          curl -f http://localhost/health || exit 1
          
          # æ¸…ç†æ—§é•œåƒ
          docker image prune -f
```

### 3.2 éƒ¨ç½²è„šæœ¬
```bash
#!/bin/bash
# scripts/deploy.sh

set -e

# é…ç½®å˜é‡
PROJECT_DIR="/opt/interview-genius"
BACKUP_DIR="/opt/backups"
DATE=$(date +%Y%m%d_%H%M%S)

echo "ğŸš€ å¼€å§‹éƒ¨ç½² InterviewGenius AI..."

# åˆ›å»ºå¤‡ä»½
echo "ğŸ“¦ åˆ›å»ºæ•°æ®åº“å¤‡ä»½..."
mkdir -p $BACKUP_DIR
docker exec interview-genius_mysql_1 mysqldump -u root -p$MYSQL_ROOT_PASSWORD interview_db > $BACKUP_DIR/db_backup_$DATE.sql

# æ›´æ–°ä»£ç 
echo "ğŸ“¥ æ›´æ–°ä»£ç ..."
cd $PROJECT_DIR
git fetch origin
git checkout main
git pull origin main

# æ„å»ºé•œåƒ
echo "ğŸ—ï¸ æ„å»ºDockeré•œåƒ..."
docker-compose build --no-cache

# æ•°æ®åº“è¿ç§»
echo "ğŸ—„ï¸ æ‰§è¡Œæ•°æ®åº“è¿ç§»..."
docker-compose run --rm backend python manage.py db upgrade

# æ»šåŠ¨æ›´æ–°æœåŠ¡
echo "ğŸ”„ æ›´æ–°æœåŠ¡..."
docker-compose up -d --remove-orphans

# ç­‰å¾…æœåŠ¡å¯åŠ¨
echo "â³ ç­‰å¾…æœåŠ¡å¯åŠ¨..."
sleep 30

# å¥åº·æ£€æŸ¥
echo "ğŸ¥ æ‰§è¡Œå¥åº·æ£€æŸ¥..."
for i in {1..10}; do
    if curl -f http://localhost/health; then
        echo "âœ… å¥åº·æ£€æŸ¥é€šè¿‡"
        break
    else
        echo "âŒ å¥åº·æ£€æŸ¥å¤±è´¥ï¼Œé‡è¯•ä¸­..."
        sleep 10
    fi
    
    if [ $i -eq 10 ]; then
        echo "âŒ éƒ¨ç½²å¤±è´¥ï¼Œæ‰§è¡Œå›æ»š..."
        # è¿™é‡Œå¯ä»¥æ·»åŠ å›æ»šé€»è¾‘
        exit 1
    fi
done

# æ¸…ç†æ—§é•œåƒ
echo "ğŸ§¹ æ¸…ç†æ—§é•œåƒ..."
docker image prune -f

echo "ğŸ‰ éƒ¨ç½²å®Œæˆï¼"
```

## 4. ç›‘æ§é…ç½®

### 4.1 Prometheusé…ç½®
```yaml
# monitoring/prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "alert_rules.yml"

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  - job_name: 'interview-genius-backend'
    static_configs:
      - targets: ['backend:5000']
    metrics_path: '/metrics'

  - job_name: 'nginx'
    static_configs:
      - targets: ['nginx:9113']

  - job_name: 'mysql'
    static_configs:
      - targets: ['mysql-exporter:9104']

  - job_name: 'redis'
    static_configs:
      - targets: ['redis-exporter:9121']

  - job_name: 'node'
    static_configs:
      - targets: ['node-exporter:9100']
```

### 4.2 å‘Šè­¦è§„åˆ™
```yaml
# monitoring/alert_rules.yml
groups:
  - name: interview-genius.rules
    rules:
      # åº”ç”¨å“åº”æ—¶é—´å‘Šè­¦
      - alert: HighResponseTime
        expr: histogram_quantile(0.95, rate(flask_request_duration_seconds_bucket[5m])) > 2
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "åº”ç”¨å“åº”æ—¶é—´è¿‡é•¿"
          description: "95%åˆ†ä½çš„å“åº”æ—¶é—´è¶…è¿‡2ç§’"

      # é”™è¯¯ç‡å‘Šè­¦
      - alert: HighErrorRate
        expr: rate(flask_request_exceptions_total[5m]) / rate(flask_request_total[5m]) > 0.05
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "åº”ç”¨é”™è¯¯ç‡è¿‡é«˜"
          description: "é”™è¯¯ç‡è¶…è¿‡5%"

      # æ•°æ®åº“è¿æ¥å‘Šè­¦
      - alert: DatabaseDown
        expr: mysql_up == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "æ•°æ®åº“è¿æ¥å¤±è´¥"
          description: "MySQLæ•°æ®åº“æ— æ³•è¿æ¥"

      # Redisè¿æ¥å‘Šè­¦
      - alert: RedisDown
        expr: redis_up == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Redisè¿æ¥å¤±è´¥"
          description: "Redisç¼“å­˜æœåŠ¡æ— æ³•è¿æ¥"

      # ç£ç›˜ç©ºé—´å‘Šè­¦
      - alert: DiskSpaceHigh
        expr: (node_filesystem_avail_bytes{mountpoint="/"} / node_filesystem_size_bytes{mountpoint="/"}) * 100 < 10
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "ç£ç›˜ç©ºé—´ä¸è¶³"
          description: "æ ¹åˆ†åŒºå‰©ä½™ç©ºé—´å°‘äº10%"

      # å†…å­˜ä½¿ç”¨å‘Šè­¦
      - alert: MemoryUsageHigh
        expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 90
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜"
          description: "å†…å­˜ä½¿ç”¨ç‡è¶…è¿‡90%"

      # CPUä½¿ç”¨å‘Šè­¦
      - alert: CPUUsageHigh
        expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "CPUä½¿ç”¨ç‡è¿‡é«˜"
          description: "CPUä½¿ç”¨ç‡è¶…è¿‡80%"
```

### 4.3 Grafanaä»ªè¡¨æ¿é…ç½®
```json
{
  "dashboard": {
    "id": null,
    "title": "InterviewGenius AI ç›‘æ§ä»ªè¡¨æ¿",
    "tags": ["interview-genius"],
    "timezone": "browser",
    "panels": [
      {
        "id": 1,
        "title": "QPS (æ¯ç§’è¯·æ±‚æ•°)",
        "type": "stat",
        "targets": [
          {
            "expr": "rate(flask_request_total[5m])",
            "legendFormat": "QPS"
          }
        ]
      },
      {
        "id": 2,
        "title": "å“åº”æ—¶é—´",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.50, rate(flask_request_duration_seconds_bucket[5m]))",
            "legendFormat": "P50"
          },
          {
            "expr": "histogram_quantile(0.95, rate(flask_request_duration_seconds_bucket[5m]))",
            "legendFormat": "P95"
          },
          {
            "expr": "histogram_quantile(0.99, rate(flask_request_duration_seconds_bucket[5m]))",
            "legendFormat": "P99"
          }
        ]
      },
      {
        "id": 3,
        "title": "é”™è¯¯ç‡",
        "type": "stat",
        "targets": [
          {
            "expr": "rate(flask_request_exceptions_total[5m]) / rate(flask_request_total[5m]) * 100",
            "legendFormat": "é”™è¯¯ç‡ (%)"
          }
        ]
      },
      {
        "id": 4,
        "title": "ç³»ç»Ÿèµ„æºä½¿ç”¨",
        "type": "graph",
        "targets": [
          {
            "expr": "100 - (avg by(instance) (irate(node_cpu_seconds_total{mode=\"idle\"}[5m])) * 100)",
            "legendFormat": "CPUä½¿ç”¨ç‡"
          },
          {
            "expr": "(1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100",
            "legendFormat": "å†…å­˜ä½¿ç”¨ç‡"
          }
        ]
      }
    ]
  }
}
```

## 5. æ—¥å¿—ç®¡ç†

### 5.1 æ—¥å¿—æ”¶é›†é…ç½®
```yaml
# logging/filebeat.yml
filebeat.inputs:
- type: log
  enabled: true
  paths:
    - /var/log/nginx/*.log
  fields:
    service: nginx
    environment: production

- type: log
  enabled: true
  paths:
    - /var/log/interview-genius/backend.log
  fields:
    service: backend
    environment: production
  multiline.pattern: '^\d{4}-\d{2}-\d{2}'
  multiline.negate: true
  multiline.match: after

output.elasticsearch:
  hosts: ["elasticsearch:9200"]
  index: "interview-genius-logs-%{+yyyy.MM.dd}"

processors:
- add_host_metadata:
    when.not.contains.tags: forwarded
```

### 5.2 æ—¥å¿—æ ¼å¼åŒ–
```python
# backend/logging_config.py
import logging
import json
from datetime import datetime

class JSONFormatter(logging.Formatter):
    def format(self, record):
        log_entry = {
            'timestamp': datetime.utcnow().isoformat(),
            'level': record.levelname,
            'message': record.getMessage(),
            'module': record.module,
            'function': record.funcName,
            'line': record.lineno,
        }
        
        if hasattr(record, 'user_id'):
            log_entry['user_id'] = record.user_id
        
        if hasattr(record, 'request_id'):
            log_entry['request_id'] = record.request_id
            
        if record.exc_info:
            log_entry['exception'] = self.formatException(record.exc_info)
            
        return json.dumps(log_entry)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    handlers=[
        logging.FileHandler('/var/log/interview-genius/backend.log'),
        logging.StreamHandler()
    ]
)

# ä¸ºä¸åŒæ¨¡å—è®¾ç½®ä¸åŒçº§åˆ«
logging.getLogger('flask').setLevel(logging.WARNING)
logging.getLogger('urllib3').setLevel(logging.WARNING)
```

## 6. å®‰å…¨é…ç½®

### 6.1 é˜²ç«å¢™è§„åˆ™
```bash
#!/bin/bash
# scripts/setup_firewall.sh

# æ¸…é™¤ç°æœ‰è§„åˆ™
iptables -F
iptables -X
iptables -t nat -F
iptables -t nat -X

# è®¾ç½®é»˜è®¤ç­–ç•¥
iptables -P INPUT DROP
iptables -P FORWARD DROP
iptables -P OUTPUT ACCEPT

# å…è®¸æœ¬åœ°å›ç¯
iptables -I INPUT -i lo -j ACCEPT

# å…è®¸å·²å»ºç«‹çš„è¿æ¥
iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT

# å…è®¸SSH (é™åˆ¶æºIP)
iptables -A INPUT -p tcp --dport 22 -s YOUR_ADMIN_IP -j ACCEPT

# å…è®¸HTTPå’ŒHTTPS
iptables -A INPUT -p tcp --dport 80 -j ACCEPT
iptables -A INPUT -p tcp --dport 443 -j ACCEPT

# å…è®¸ç›‘æ§ç«¯å£ (é™åˆ¶æºIP)
iptables -A INPUT -p tcp --dport 9090 -s MONITORING_IP -j ACCEPT
iptables -A INPUT -p tcp --dport 3001 -s MONITORING_IP -j ACCEPT

# é™åˆ¶è¿æ¥é¢‘ç‡
iptables -A INPUT -p tcp --dport 80 -m limit --limit 25/minute --limit-burst 100 -j ACCEPT
iptables -A INPUT -p tcp --dport 443 -m limit --limit 25/minute --limit-burst 100 -j ACCEPT

# ä¿å­˜è§„åˆ™
iptables-save > /etc/iptables/rules.v4
```

### 6.2 SSLè¯ä¹¦è‡ªåŠ¨ç»­æœŸ
```bash
#!/bin/bash
# scripts/renew_ssl.sh

# ä½¿ç”¨certbotè‡ªåŠ¨ç»­æœŸ
certbot renew --nginx --non-interactive --agree-tos --email admin@interview-genius.com

# é‡å¯nginx
docker-compose restart nginx

# æ£€æŸ¥è¯ä¹¦æœ‰æ•ˆæœŸ
certbot certificates
```

## 7. å¤‡ä»½ç­–ç•¥

### 7.1 æ•°æ®åº“å¤‡ä»½è„šæœ¬
```bash
#!/bin/bash
# scripts/backup_database.sh

set -e

BACKUP_DIR="/opt/backups/mysql"
DATE=$(date +%Y%m%d_%H%M%S)
RETENTION_DAYS=30

# åˆ›å»ºå¤‡ä»½ç›®å½•
mkdir -p $BACKUP_DIR

# å¤‡ä»½æ•°æ®åº“
docker exec interview-genius_mysql_1 mysqldump \
  -u root \
  -p$MYSQL_ROOT_PASSWORD \
  --single-transaction \
  --routines \
  --triggers \
  interview_db | gzip > $BACKUP_DIR/interview_db_$DATE.sql.gz

# ä¸Šä¼ åˆ°äº‘å­˜å‚¨ (ç¤ºä¾‹ä½¿ç”¨AWS S3)
aws s3 cp $BACKUP_DIR/interview_db_$DATE.sql.gz s3://interview-genius-backups/mysql/

# æ¸…ç†æœ¬åœ°æ—§å¤‡ä»½
find $BACKUP_DIR -name "*.sql.gz" -mtime +$RETENTION_DAYS -delete

echo "æ•°æ®åº“å¤‡ä»½å®Œæˆ: interview_db_$DATE.sql.gz"
```

### 7.2 æ–‡ä»¶å¤‡ä»½è„šæœ¬
```bash
#!/bin/bash
# scripts/backup_files.sh

set -e

BACKUP_DIR="/opt/backups/files"
DATE=$(date +%Y%m%d_%H%M%S)
RETENTION_DAYS=7

# åˆ›å»ºå¤‡ä»½ç›®å½•
mkdir -p $BACKUP_DIR

# å¤‡ä»½ä¸Šä¼ æ–‡ä»¶
tar -czf $BACKUP_DIR/uploads_$DATE.tar.gz -C /opt/interview-genius uploads/

# ä¸Šä¼ åˆ°äº‘å­˜å‚¨
aws s3 cp $BACKUP_DIR/uploads_$DATE.tar.gz s3://interview-genius-backups/files/

# æ¸…ç†æœ¬åœ°æ—§å¤‡ä»½
find $BACKUP_DIR -name "*.tar.gz" -mtime +$RETENTION_DAYS -delete

echo "æ–‡ä»¶å¤‡ä»½å®Œæˆ: uploads_$DATE.tar.gz"
```

## 8. ç¯å¢ƒé…ç½®

### 8.1 ç”Ÿäº§ç¯å¢ƒå˜é‡
```bash
# .env.production
# æ•°æ®åº“é…ç½®
MYSQL_ROOT_PASSWORD=your_secure_password
MYSQL_PASSWORD=your_secure_password

# åº”ç”¨é…ç½®
SECRET_KEY=your_super_secret_key
JWT_SECRET_KEY=your_jwt_secret_key
FLASK_ENV=production

# Redisé…ç½®
REDIS_PASSWORD=your_redis_password

# ç›‘æ§é…ç½®
GRAFANA_PASSWORD=your_grafana_password

# é‚®ä»¶é…ç½®
MAIL_SERVER=smtp.gmail.com
MAIL_PORT=587
MAIL_USERNAME=your_email@gmail.com
MAIL_PASSWORD=your_email_password

# OpenAIé…ç½®
OPENAI_API_KEY=your_openai_api_key

# äº‘å­˜å‚¨é…ç½®
AWS_ACCESS_KEY_ID=your_aws_access_key
AWS_SECRET_ACCESS_KEY=your_aws_secret_key
AWS_S3_BUCKET=interview-genius-storage
```

### 8.2 ç³»ç»Ÿä¼˜åŒ–é…ç½®
```bash
# /etc/sysctl.conf ä¼˜åŒ–
# ç½‘ç»œä¼˜åŒ–
net.core.somaxconn = 65535
net.core.netdev_max_backlog = 5000
net.ipv4.tcp_max_syn_backlog = 65535
net.ipv4.tcp_keepalive_time = 600
net.ipv4.tcp_keepalive_intvl = 60
net.ipv4.tcp_keepalive_probes = 10

# å†…å­˜ä¼˜åŒ–
vm.swappiness = 10
vm.dirty_ratio = 15
vm.dirty_background_ratio = 5

# æ–‡ä»¶æè¿°ç¬¦é™åˆ¶
fs.file-max = 65535

# åº”ç”¨ç³»ç»Ÿä¼˜åŒ–
sysctl -p
```

è¿™ä»½è¿ç»´éƒ¨ç½²æ–‡æ¡£æä¾›äº†å®Œæ•´çš„å®¹å™¨åŒ–éƒ¨ç½²æ–¹æ¡ˆï¼ŒåŒ…å«äº†Dockeré…ç½®ã€Nginxåå‘ä»£ç†ã€CI/CDæµç¨‹ã€ç›‘æ§å‘Šè­¦ã€æ—¥å¿—ç®¡ç†ã€å®‰å…¨é…ç½®å’Œå¤‡ä»½ç­–ç•¥ï¼Œä¸ºç”Ÿäº§ç¯å¢ƒçš„ç¨³å®šè¿è¡Œæä¾›äº†å…¨é¢ä¿éšœã€‚ 